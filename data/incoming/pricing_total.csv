厂商,模型名称,官方输入价格/M token,官方输出价格/M token,模型说明,温度范围,默认温度,模型地区,是否常用模型,是否收藏
ChatGPT（Open AI）,gpt-5,￥8.90,￥71.20,跨领域编码与智能体任务中表现最出色的模型,[0-2],1,国外,"是
",
ChatGPT（Open AI）,gpt-5-mini,￥1.78,￥14.24,用于明确定义任务的更快速且高性价比版本的 GPT-5,[0-2],1,国外,是,
ChatGPT（Open AI）,gpt-5-nano,￥0.36,￥2.85,GPT-5 的最快且最具性价比版本，特别适用于摘要和分类任务。,[0-2],1,国外,,
ChatGPT（Open AI）,GPT-5 chat-latest,￥8.90,￥71.20,这些模型用于 ChatGPT，不推荐在 API 中使用。GPT-5 Chat 指的是当前 ChatGPT 所使用的 GPT-5 快照。我们建议在大多数 API 场景中使用 GPT-5，但如果你想测试我们在聊天场景中的最新改进，可以尝试使用这个 GPT-5 Chat 模型。,[0-2],1,国外,,
ChatGPT（Open AI）,gpt-4.1,￥14.24,￥56.96,最智能的非推理模型。GPT-4.1 在指令遵循和工具调用方面表现出色，具备广泛的跨领域知识。它拥有 100 万 token 的上下文窗口，并在无推理步骤的情况下实现低延迟响应。,[0-2],1,国外,是,
ChatGPT（Open AI）,gpt-4.1-mini,￥2.85,￥11.39,"GPT-4.1 的更小、更快速版本。
",[0-2],1,国外,,
ChatGPT（Open AI）,gpt-4.1-nano,￥0.71,￥2.85,GPT-4.1 的最快且最具性价比版本。,[0-2],1,国外,,
ChatGPT（Open AI）,gpt-4o,￥17.80,￥71.20,快速、智能且灵活的 GPT 模型。GPT-4o（“o” 代表 “omni”）是我们通用型、高智能的旗舰模型。它可接受文本和图像输入，并生成文本输出（包括结构化输出）。它是适用于大多数任务的最佳模型，也是除 o 系列外我们性能最强的模型。,[0-2],1,国外,是,
ChatGPT（Open AI）,gpt-4o-mini,￥1.07,￥4.27,GPT-4o mini（“o”代表“omni”）是一款快速、经济的小型模型，适用于专注型任务。它接受文本和图像输入，并生成文本输出（包括结构化输出）。它非常适合进行微调，并且像 GPT-4o 这样的大型模型的输出可以提炼到 GPT-4o-mini 中，从而以更低的成本和延迟产生类似的结果。,[0-2],1,国外,,
Gemini（Google）,gemini-2.5-pro（200k）,￥8.90,￥71.20,Google 旗下先进的多用途模型，擅长处理编码和复杂的推理任务。,[0-2],1,国外,是,
Gemini（Google）,gemini-2.5-flash,￥2.14,￥17.80,我们的首个混合推理模型，支持 100 万个 token 的上下文窗口，并具有思考预算。,[0-2],1,国外,是,
Gemini（Google）,gemini-2.5-flash-preview,￥2.14,￥17.80,基于 2.5 Flash 模型的最新模型。2.5 Flash 预览版最适合大规模处理、低延迟、需要思考的高数据量任务以及代理应用场景。,[0-2],1,国外,,
Gemini（Google）,gemini-2.5-flash-lite-preview,￥0.71,￥2.85,基于 Gemini 2.5 Flash Lite （Google 旗下最小巧且最具成本效益的模型，专为大规模使用而打造。）的最新模型，经过优化，可实现高成本效益、高吞吐量和高质量。,[0-2],1,国外,,
Gemini（Google）,gemini-2.0-flash,￥0.71,￥2.85,Google 旗下最均衡的多模态模型，在所有任务中均表现出色，支持长达 100 万个 token 的上下文窗口，专为智能体时代而打造。,[0-2],1,国外,,
Gemini（Google）,gemini-2.0-flash-lite,￥0.57,￥2.14,Google 旗下最小巧且最具成本效益的模型，专为大规模使用而打造。,[0-2],1,国外,,
Claude（Anthropic）,Claude Sonnet 4.5,￥21.36,￥106.80,复杂代理和编程的最佳模型，在大多数任务中具有最高智能，在长时间运行的自主任务中具有卓越的工具编排能力,[0-1],1,国外,是,
Claude（Anthropic）,Claude Haiku 4.5,￥7.12,￥35.60,具有闪电般速度和扩展思维的近前沿性能 - 我们最快、最智能的Haiku模型，价格最经济,[0-1],1,国外,,
Claude（Anthropic）,Claude Sonnet 4,￥21.36,￥106.80,Claude Sonnet 4.5的旧版本,[0-1],1,国外,是,
Claude（Anthropic）,Claude Opus 4.1,￥106.80,￥534.00,专业复杂任务的卓越智能和推理能力,[0-1],1,国外,,
Claude（Anthropic）,Claude Opus 4,￥106.80,￥534.00,Claude Opus 4.1的旧版本,[0-1],1,国外,,
豆包（字节跳动）,doubao-seed-1.6-flash,￥0.15,￥1.50,有极致推理速度的多模态深度思考模型；同时支持文本和视觉理解。文本理解能力超过上一代 Lite 系列模型，视觉理解比肩友商 Pro 系列模型。,[0-2],1,国内,,
豆包（字节跳动）,doubao-seed-1.6（32k，0.2k）,￥0.80,￥2.00,全新多模态深度思考模型，支持手动开关深度思考能力。其中 non-thinking 模式对比上一代模型大幅提升。,[0-2],1,国内,是,
豆包（字节跳动）,doubao-seed-1.6（32k，♾️）,￥0.80,￥8.00,全新多模态深度思考模型，支持手动开关深度思考能力。其中 non-thinking 模式对比上一代模型大幅提升。,[0-2],1,国内,,
豆包（字节跳动）,doubao-seed-1.6-thinking（32k）,￥0.80,￥8.00,在思考能力上进行了大幅强化， 对比 doubao 1.5 代深度理解模型，在编程、数学、逻辑推理等基础能力上进一步提升， 支持视觉理解。,[0-2],1,国内,,
豆包（字节跳动）,doubao-1.5-pro-32k,￥0.80,￥2.00,相比 doubao-1.0 模型，性能全面升级，在知识、代码、推理等方面表现卓越。输出长度支持最大 12k tokens。同时提供面向角色扮演领域优化版本。,[0-2],1,国内,,
豆包（字节跳动）,doubao-1.5-vision-pro,￥3.00,￥9.00,doubao-1.5-vision-pro，全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。,[0-2],1,国内,,
通义千问（阿里云）,qwen3-max（32k）,￥6.00,￥24.00,通义千问系列效果最好的模型，适合复杂、多步骤的任务，暂不支持深度思考,[0-2）,0.7,国内,是,
通义千问（阿里云）,qwen3-omni-flash(输入：文本)（32k）,￥1.80,￥6.90,Qwen-Omni 模型能够接收文本、图片、音频、视频等多种模态的组合输入，并生成文本或语音形式的回复， 提供多种拟人音色，支持多语言和方言的语音输出，可应用于文本创作、视觉识别、语音助手等场景。,[0-2）,0.9,国内,,
通义千问（阿里云）,qwen3-omni-flash(输入：图片)（32k）,￥3.30,￥12.70,Qwen-Omni 模型能够接收文本、图片、音频、视频等多种模态的组合输入，并生成文本或语音形式的回复， 提供多种拟人音色，支持多语言和方言的语音输出，可应用于文本创作、视觉识别、语音助手等场景。,[0-2）,0.9,国内,,
通义千问（阿里云）,qwen3-vl-plus（32k）,￥1.00,￥10.00,通义千问VL是具有视觉（图像）理解能力的文本生成模型，不仅能进行OCR（图片文字识别），还能进一步总结和推理，例如从商品照片中提取属性，根据习题图进行解题等,[0-2）,0.8,国内,,
通义千问（阿里云）,qwen3-coder-plus（32k）,￥4.00,￥16.00,通义千问代码模型。最新的 Qwen3-Coder-Plus 系列模型是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程，代码能力卓越的同时兼具通用能力。,[0-2）,0.7,国内,,
通义千问（阿里云）,qwen3-coder-flash（32k）,￥1.00,￥4.00,通义千问代码模型。最新的 Qwen3-Coder-Plus 系列模型是基于 Qwen3 的代码生成模型，具有强大的Coding Agent能力，擅长工具调用和环境交互，能够实现自主编程，代码能力卓越的同时兼具通用能力。,[0-2）,0.7,国内,,
通义千问（阿里云）,qwen-Turbo,￥0.30,￥0.60,通义千问Turbo 后续不再更新，建议替换为通义千问Flash。通义千问Flash采用灵活的阶梯定价，计费更合理,[0-2）,0.7,国内,,
通义千问（阿里云）,qwen-Plus（非思考模式）（128k）,￥0.80,￥2.00,能力均衡，推理效果、成本和速度介于通义千问Max和通义千问Flash之间，适合中等复杂任务。,[0-2）,0.7,国内,是,
通义千问（阿里云）,qwen-Plus（思考模式）（128k）,￥0.80,￥8.00,能力均衡，推理效果、成本和速度介于通义千问Max和通义千问Flash之间，适合中等复杂任务。,[0-2）,0.7,国内,,
通义千问（阿里云）,qwen-Max（20240919）,￥2.40,￥9.60,通义千问系列效果最好的模型，适合复杂、多步骤的任务,[0-2）,0.7,国内,,
通义千问（阿里云）,qwen-QWQ-Plus,￥1.60,￥4.00,基于 Qwen2.5 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平,[0-2）,0.5,国内,,
通义千问（阿里云）,qwen-QWQ-32B,￥2.00,￥6.00,基于 Qwen2.5-32B 模型训练的 QwQ 推理模型，通过强化学习大幅度提升了模型推理能力。模型数学代码等核心指标（AIME 24/25、LiveCodeBench）以及部分通用指标（IFEval、LiveBench等）达到DeepSeek-R1 满血版水平，各指标均显著超过同样基于 Qwen2.5-32B 的 DeepSeek-R1-Distill-Qwen-32B,[0-2）,0.7,国内,,
通义千问（阿里云）,qwen-flash（128k）,￥0.15,￥1.50,通义千问系列速度最快、成本极低的模型，适合简单任务。通义千问Flash采用灵活的阶梯定价，相比通义千问Turbo计费更合理。,[0-2）,0.7,国内,是,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
,,,,,,,,,
